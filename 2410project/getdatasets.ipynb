{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eastern and Western Conference standings saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Basketball Reference page\n",
    "url = \"https://www.basketball-reference.com/leagues/NBA_2020.html\"\n",
    "\n",
    "# Send a request to the page\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Define a function to parse the standings table\n",
    "def parse_table(table_id, conference_name):\n",
    "    table = soup.find(\"table\", {\"id\": table_id})\n",
    "    headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")]  # Include the team name header\n",
    "    data = []\n",
    "    rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        if row.find(\"th\", {\"scope\": \"row\"}):  # Exclude separator rows\n",
    "            # Extract team name\n",
    "            team_name = row.find(\"th\", {\"scope\": \"row\"}).text.strip()\n",
    "            # Extract stats\n",
    "            cells = row.find_all(\"td\")\n",
    "            row_data = [team_name] + [cell.text.strip() for cell in cells]\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df.insert(0, \"Conference\", conference_name)  # Add a conference column\n",
    "    return df\n",
    "\n",
    "\n",
    "# Parse Eastern and Western Conference tables\n",
    "eastern_df = parse_table(\"confs_standings_E\", \"Eastern Conference\")\n",
    "western_df = parse_table(\"confs_standings_W\", \"Western Conference\")\n",
    "\n",
    "# Save the data into CSV files\n",
    "eastern_df.to_csv(\"NBA_2020_Eastern_Conference_Standings.csv\", index=False)\n",
    "western_df.to_csv(\"NBA_2020_Western_Conference_Standings.csv\", index=False)\n",
    "\n",
    "# Display success message\n",
    "print(\"Eastern and Western Conference standings saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to NBA_Champions_Last_5_Seasons_Updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Updated Data for the NBA Champions\n",
    "champions_data = [\n",
    "    {\n",
    "        \"Season\": \"2023-24\",\n",
    "        \"Champion\": \"Boston Celtics\",\n",
    "        \"Finals MVP\": \"Jaylen Brown\",\n",
    "        \"Coach\": \"Joe Mazulla\",\n",
    "        \"Record\": \"64-18\",\n",
    "        \"Playoff Record\": \"16-3\",\n",
    "        \"Playoff Opponents\": [\n",
    "            \"Miami Heat (4-1)\",\n",
    "            \"Cleveland Cavaliers (4-1)\",\n",
    "            \"Indiana Pacers (4-0)\",\n",
    "            \"Dallas Mavericks (4-1)\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"Season\": \"2022-23\",\n",
    "        \"Champion\": \"Denver Nuggets\",\n",
    "        \"Finals MVP\": \"Nikola JokiÄ‡\",\n",
    "        \"Coach\": \"Michael Malone\",\n",
    "        \"Record\": \"53-29\",\n",
    "        \"Playoff Record\": \"16-4\",\n",
    "        \"Playoff Opponents\": [\n",
    "            \"Minnesota Timberwolves (4-1)\",\n",
    "            \"Phoenix Suns (4-2)\",\n",
    "            \"Los Angeles Lakers (4-0)\",\n",
    "            \"Miami Heat (4-1)\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"Season\": \"2021-22\",\n",
    "        \"Champion\": \"Golden State Warriors\",\n",
    "        \"Finals MVP\": \"Stephen Curry\",\n",
    "        \"Coach\": \"Steve Kerr\",\n",
    "        \"Record\": \"53-29\",\n",
    "        \"Playoff Record\": \"16-6\",\n",
    "        \"Playoff Opponents\": [\n",
    "            \"Denver Nuggets (4-1)\",\n",
    "            \"Memphis Grizzlies (4-2)\",\n",
    "            \"Dallas Mavericks (4-1)\",\n",
    "            \"Boston Celtics (4-2)\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"Season\": \"2020-21\",\n",
    "        \"Champion\": \"Milwaukee Bucks\",\n",
    "        \"Finals MVP\": \"Giannis Antetokounmpo\",\n",
    "        \"Coach\": \"Mike Budenholzer\",\n",
    "        \"Record\": \"46-26\",\n",
    "        \"Playoff Record\": \"16-7\",\n",
    "        \"Playoff Opponents\": [\n",
    "            \"Miami Heat (4-0)\",\n",
    "            \"Brooklyn Nets (4-3)\",\n",
    "            \"Atlanta Hawks (4-2)\",\n",
    "            \"Phoenix Suns (4-2)\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"Season\": \"2019-20\",\n",
    "        \"Champion\": \"Los Angeles Lakers\",\n",
    "        \"Finals MVP\": \"LeBron James\",\n",
    "        \"Coach\": \"Frank Vogel\",\n",
    "        \"Record\": \"52-19\",\n",
    "        \"Playoff Record\": \"16-5\",\n",
    "        \"Playoff Opponents\": [\n",
    "            \"Portland Trail Blazers (4-1)\",\n",
    "            \"Houston Rockets (4-1)\",\n",
    "            \"Denver Nuggets (4-1)\",\n",
    "            \"Miami Heat (4-2)\"\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df_champions = pd.DataFrame(champions_data)\n",
    "\n",
    "# Convert \"Playoff Opponents\" list to a single string\n",
    "df_champions[\"Playoff Opponents\"] = df_champions[\"Playoff Opponents\"].apply(lambda x: \", \".join(x))\n",
    "\n",
    "# Save to a CSV file\n",
    "file_path = \"NBA_Champions_Last_5_Seasons_Updated.csv\"\n",
    "df_champions.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coaching record table saved to Frank_Vogel_Coaching_Record_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "##getting the championship coaches' datasets\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL for the coach's Basketball Reference page\n",
    "url = \"https://www.basketball-reference.com/coaches/vogelfr99c.html\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the coaching record table\n",
    "table = soup.find(\"table\", {\"id\": \"coach-stats\"})\n",
    "\n",
    "# Check if the table is found\n",
    "if not table:\n",
    "    print(\"No coaching record table found on the page.\")\n",
    "else:\n",
    "    # Extract the headers (cleaning up multi-level headers)\n",
    "    raw_headers = table.find(\"thead\").find_all(\"tr\")\n",
    "    headers = [th.text.strip() for th in raw_headers[1].find_all(\"th\")]  # Use second row of headers\n",
    "\n",
    "    # Extract table rows\n",
    "    data = []\n",
    "    rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        # Skip rows without valid season data\n",
    "        row_header = row.find(\"th\", {\"scope\": \"row\"})\n",
    "        if row_header and \"Assistant Coach\" not in row.text:  # Exclude \"Assistant Coach\" rows\n",
    "            # Extract row data\n",
    "            cells = [cell.text.strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "            data.append(cells)\n",
    "\n",
    "    # Check if any valid rows were extracted\n",
    "    if not data:\n",
    "        print(\"No valid rows found in the coaching record table.\")\n",
    "    else:\n",
    "        # Create a DataFrame\n",
    "        coaching_record_df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "        # Save to a CSV file\n",
    "        file_path = \"Frank_Vogel_Coaching_Record_Cleaned.csv\"\n",
    "        coaching_record_df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"Coaching record table saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as Milwaukee_Bucks_2020_21_Team_Misc_Stats.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data for the 2020-21 Milwaukee Bucks Team Miscellaneous Stats\n",
    "bucks_misc_20_21_data = {\n",
    "    \"Category\": [\n",
    "        \"W\", \"L\", \"PW\", \"PL\", \"MOV\", \"SOS\", \"SRS\", \"ORtg\", \"DRtg\", \"Pace\",\n",
    "        \"FTr\", \"3PAr\", \"eFG%\", \"TOV%\", \"ORB%\", \"FT/FGA\", \"eFG%\", \"TOV%\", \n",
    "        \"DRB%\", \"FT/FGA\", \"Arena\", \"Attendance\"\n",
    "    ],\n",
    "    \"Team\": [\n",
    "        46, 26, 48, 24, 5.89, -0.32, 5.57, 117.2, 111.4, 102.2, \n",
    "        0.233, 0.404, 0.566, 12.0, 23.3, 0.177, 0.536, 11.5, \n",
    "        79.7, 0.157, \"Fiserv Forum\", \"64,780\"\n",
    "    ],\n",
    "    \"Lg Rank\": [\n",
    "        7, 24, 5, 5, 3, 30, 4, 6, 10, 2, \n",
    "        24, 12, 2, 12, 9, 26, 13, 24, \n",
    "        3, 1, \"\", 10\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "bucks_misc_20_21_df = pd.DataFrame(bucks_misc_20_21_data)\n",
    "\n",
    "# Save to CSV\n",
    "file_path = \"Milwaukee_Bucks_2020_21_Team_Misc_Stats.csv\"\n",
    "bucks_misc_20_21_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved as {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Finals_Four_Factors_2022_23_and_2023_24.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24028\\935005749.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Load the existing Finals Four Factors dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mexisting_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Finals_Four_Factors_2022_23_and_2023_24.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mexisting_finals_four_factors_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexisting_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Create a new DataFrame for the additional data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Finals_Four_Factors_2022_23_and_2023_24.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adding data for 2019-20, 2020-21, and 2021-22 Finals Four Factors\n",
    "additional_finals_four_factors = {\n",
    "    \"Category\": [\"Pace\", \"eFG%\", \"TOV%\", \"ORB%\", \"FT/FGA\", \"ORtg\", \"PTS\"],\n",
    "    \"2019_20_LAL\": [94.1, 0.547, 13.0, 27.3, 0.200, 116.9, 110.0],\n",
    "    \"2019_20_MIA\": [94.1, 0.534, 12.1, 16.3, 0.247, 111.1, 104.5],\n",
    "    \"2020_21_MIL\": [96.0, 0.529, 10.2, 29.2, 0.190, 116.3, 111.7],\n",
    "    \"2020_21_PHO\": [96.0, 0.555, 12.3, 17.4, 0.176, 113.8, 109.3],\n",
    "    \"2021_22_GSW\": [95.3, 0.533, 12.9, 22.7, 0.136, 110.0, 104.8],\n",
    "    \"2021_22_BOS\": [95.3, 0.522, 15.6, 23.3, 0.180, 105.8, 100.8]\n",
    "}\n",
    "\n",
    "# Load the existing Finals Four Factors dataset\n",
    "existing_file_path = \"Finals_Four_Factors_2022_23_and_2023_24.csv\"\n",
    "existing_finals_four_factors_df = pd.read_csv(existing_file_path)\n",
    "\n",
    "# Create a new DataFrame for the additional data\n",
    "additional_finals_four_factors_df = pd.DataFrame(additional_finals_four_factors)\n",
    "\n",
    "# Combine the datasets\n",
    "combined_finals_four_factors_df = pd.concat(\n",
    "    [existing_finals_four_factors_df, additional_finals_four_factors_df.drop(columns=[\"Category\"])],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Update Category column for better readability\n",
    "combined_finals_four_factors_df[\"Category\"] = additional_finals_four_factors[\"Category\"]\n",
    "\n",
    "# Save the combined dataset\n",
    "combined_file_path = \"Combined_Finals_Four_Factors.csv\"\n",
    "combined_finals_four_factors_df.to_csv(combined_file_path, index=False)\n",
    "\n",
    "print(f\"Combined dataset saved as {combined_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home record for Miami Heat with point differentials saved to heat_home_record_with_point_differentials_2020_2021.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\19092\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "##print home records of finals teams\n",
    "\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the Heat's games\n",
    "team_id = \"1610612748\"  # Miami Heat Team ID\n",
    "gamefinder = leaguegamefinder.LeagueGameFinder(team_id_nullable=team_id, season_nullable=\"2020-21\")\n",
    "\n",
    "# Convert data to DataFrame\n",
    "games = gamefinder.get_data_frames()[0]\n",
    "\n",
    "# Filter home games\n",
    "home_games = games[games['MATCHUP'].str.contains('vs.')]\n",
    "\n",
    "# Use PLUS_MINUS if PTS_OPP is not available\n",
    "if 'PTS' in home_games.columns and 'PTS_OPP' in home_games.columns:\n",
    "    home_games['POINT_DIFFERENTIAL'] = home_games['PTS'] - home_games['PTS_OPP']\n",
    "elif 'PLUS_MINUS' in home_games.columns:\n",
    "    home_games['POINT_DIFFERENTIAL'] = home_games['PLUS_MINUS']\n",
    "else:\n",
    "    print(\"Error: Columns for points or PLUS_MINUS not found.\")\n",
    "    home_games['POINT_DIFFERENTIAL'] = None\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = ['GAME_DATE', 'MATCHUP', 'RESULT', 'PTS', 'POINT_DIFFERENTIAL']\n",
    "available_columns = [col for col in selected_columns if col in home_games.columns]\n",
    "home_record = home_games[available_columns]\n",
    "\n",
    "# Save to CSV\n",
    "csv_file_path = \"heat_home_record_with_point_differentials_2020_2021.csv\"\n",
    "home_record.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Home record for Miami Heat with point differentials saved to {csv_file_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
